{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff3e233-9d91-40ed-a76e-41dff0e61863",
   "metadata": {},
   "source": [
    "## Ski Rental with Movie Lens and CitiBike\n",
    "This notebook trains predictors for whether a user will watch more than b movies in the next month. \n",
    "We use these raw and calibrated predictors to compare the results of the ski-rental algorithms we propose in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd96b7-680e-4c90-8305-e11a6bf7ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme() \n",
    "# features\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "#calibration library\n",
    "from crepes import WrapRegressor\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import tree\n",
    "\n",
    "import models as md\n",
    "import utils as ut\n",
    "import calibrator as cal\n",
    "import skirental as sr\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fde1d7-3f1c-4708-afb3-d247497adabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f83af-5a7b-4cd4-81c5-6b90a103ae94",
   "metadata": {},
   "source": [
    "### Section 0: Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789bc52f-aa0d-4f39-bed7-1912f69af649",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'Bike'\n",
    "\n",
    "if DATASET == 'Movies': \n",
    "    movie_df = pd.read_csv('clean_data/movie_lens100k_monthly.csv')\n",
    "    y = movie_df['movies_this_month'].values\n",
    "    # Transform both feature sets\n",
    "    X_clf = movie_df[['age', 'gender', 'occupation', 'zip', 'movies_watched']]\n",
    "    X_reg = movie_df[['age', 'gender', 'movies_watched']]\n",
    "\n",
    "    # Create separate DictVectorizers for each feature set\n",
    "    vec_clf = DictVectorizer()\n",
    "    vec_reg = DictVectorizer()\n",
    "\n",
    "    X_post_clf = vec_clf.fit_transform(X_clf.to_dict('records')).toarray()\n",
    "    X_post_reg = vec_reg.fit_transform(X_reg.to_dict('records')).toarray()\n",
    "elif DATASET == 'Bike': \n",
    "    n=10000\n",
    "    bike_df = pd.read_csv('clean_data/citibike-june2015.csv').dropna().sample(n)\n",
    "    #june_bike_df = pd.read_csv('clean_data/citibike-june2015.csv').dropna().sample(n)\n",
    "    \n",
    "    #fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "    #sns.histplot(bike_df['tripduration'].values, ax=axes[0])\n",
    "    #sns.histplot(june_bike_df['tripduration'].values, ax=axes[1])\n",
    "    \n",
    "    bike_df = bike_df[bike_df['start station name']!= bike_df['end station name']]\n",
    "\n",
    "    #joint_df = ut.uniform_subsample_df(bike_df, 'tripduration', n_bins=10, samples_per_bin=1000) #.sample(n)\n",
    "    #print(joint_df.shape)\n",
    "    joint_df = bike_df\n",
    "    # positive = bike_df[bike_df['tripduration'] >= b].sample(int(n/2))\n",
    "    # negative = bike_df[bike_df['tripduration'] < b].sample(int(n/2))\n",
    "    # joint_df = pd.concat([positive, negative])\n",
    "\n",
    "    X = joint_df[['birth year', 'gender', 'usertype', 'start latitude rounded', 'start longitude rounded', 'end latitude rounded']] #, 'end longitude rounded', 'starthour']]\n",
    "    y = joint_df['tripduration'].values\n",
    "\n",
    "    \n",
    "\n",
    "    # Create separate DictVectorizers for each feature set\n",
    "    vec_clf = DictVectorizer()\n",
    "    vec_reg = DictVectorizer()\n",
    "\n",
    "    X_post_clf = vec_clf.fit_transform(X.to_dict('records')).toarray()\n",
    "    X_post_reg = vec_reg.fit_transform(X.to_dict('records')).toarray()\n",
    "\n",
    "# sns.histplot(y)\n",
    "# quantiles = joint_df['tripduration'].quantile([0.25, 0.5, 0.75])\n",
    "# for q in quantiles:\n",
    "#     print(q)\n",
    "#     plt.axvline(q, color='red', linestyle='--')\n",
    "# plt.xlabel('target value')\n",
    "# plt.title(f'Distribution of target values for {DATASET} dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6030b2b-5a2e-4b78-a318-e56214e6a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69df44e-f5b1-41bd-87ff-8dfedcfbbffa",
   "metadata": {},
   "source": [
    "### Section 1: Training & Calibrating Predictors\n",
    "This section is to verify the achievable accuracy / perforamnce of predictors on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ff8be-a9ca-47ec-a18c-393883af1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training calibrated regression model: \n",
    "i=0\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_post_reg, y, test_size=0.20, random_state=i)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train, y_train, test_size=0.20, random_state=i)\n",
    "\n",
    "print(f\"size train: {len(X_train)}, valid: {len(X_valid)} test: {len(X_test)} \")\n",
    "\n",
    "for clf in md.reg_dict: \n",
    "    start_time = time.time()\n",
    "    model = Pipeline(\n",
    "                [\n",
    "                    (\"scalar\", StandardScaler()),\n",
    "                    (\"reg\", md.reg_dict[clf]())\n",
    "                ]\n",
    "            )\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{clf}: {model.score(X_test, y_test)}\")\n",
    "    rf = WrapRegressor(model)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf.calibrate(X_valid, y_valid)\n",
    "    for conf in [0.7, 0.8, 0.9, 0.95]: \n",
    "        conf_interval = rf.predict_int(X_test, confidence=conf)\n",
    "        print(f'conf: {conf} interval size: {(conf_interval[:, 1] - conf_interval[:, 0]).mean()}')\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time \n",
    "    print(f\"Function took {execution_time} seconds to execute\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd84649-8afc-46b9-99a6-d23c3cd0a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = [] \n",
    "num_runs = 1\n",
    "binary_clfs = {} \n",
    "calibrators = {} \n",
    "bins = 50 \n",
    "temp_b = 600\n",
    "for i in range(num_runs): \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_post_clf, y>temp_b, test_size=0.20, random_state=i)\n",
    "\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                X_train, y_train, test_size=0.20, random_state=i)\n",
    "\n",
    "        for name in md.clf_dict: \n",
    "            start_time = time.time()\n",
    "            curr_clf = md.model_choice(name, X_train, y_train)\n",
    "            curr_clf.fit(X_train, y_train)\n",
    "            probs = curr_clf.predict_proba(X_test)[:, 1]\n",
    "            _, _, ece_l1, ece_l2, alpha, = ut.expected_calibration_error(prob_true=np.asarray(y_test), \n",
    "                                                                 prob_pred=np.asarray(probs), \n",
    "                                                                 num_bins=bins)\n",
    "            training_results.append({\n",
    "                'clf': name, \n",
    "                'run': i, \n",
    "                'ece_l1': ece_l1, \n",
    "                'ece_l2': ece_l2, \n",
    "                'alpha': alpha,\n",
    "                'accuracy': curr_clf.score(X_test, y_test), \n",
    "                'auc': roc_auc_score(y_test, probs),\n",
    "                'calibrated': False\n",
    "            })\n",
    "            binary_clfs[name] = curr_clf\n",
    "\n",
    "            calibrator = cal.BinningCalibrator(bins=bins)\n",
    "            calibrator.calibrate(curr_clf.predict_proba(X_valid)[:, 1], y_valid)\n",
    "            y_cal_probs = calibrator.transform(probs)\n",
    "            _, _, ece_l1, ece_l2, alpha = ut.expected_calibration_error(prob_true=np.asarray(y_test),\n",
    "                                                                 prob_pred=np.asarray(y_cal_probs),\n",
    "                                                                 num_bins=bins)\n",
    "            training_results.append({\n",
    "                'clf': name, \n",
    "                'run': i, \n",
    "                'ece_l1': ece_l1, \n",
    "                'ece_l2': ece_l2, \n",
    "                'alpha': alpha,\n",
    "                'accuracy': ((y_cal_probs > 0.5) ==  y_test).mean(), \n",
    "                'auc': roc_auc_score(y_test, y_cal_probs),\n",
    "                'calibrated': True\n",
    "            })\n",
    "            calibrators[name] = calibrator\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time \n",
    "            print(f\"{name} took {execution_time} seconds to execute\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afecdf-bad4-4f08-8c0b-f42f2a1cf70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results_df = pd.DataFrame(training_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afebf4-f774-4030-b4c6-d1b8ada54323",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "metrics = ['ece_l1', 'ece_l2', 'accuracy', 'auc']\n",
    "titles = ['ECE (L1)', 'ECE (L2)', 'Accuracy', 'AUC']\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Create subplots\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    sns.barplot(\n",
    "        data=training_results_df,\n",
    "        x='clf',\n",
    "        y=metric,\n",
    "        hue='calibrated',\n",
    "        ax=axes[idx],\n",
    "    )\n",
    "    axes[idx].set_title(title)\n",
    "    axes[idx].set_xlabel('Classifier')\n",
    "    axes[idx].set_ylabel(title)\n",
    "    # Rotate x-axis labels for better readability\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    # Move legend to a better position\n",
    "    axes[idx].legend(title='')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841676c-9397-498b-8da0-e219c0404f16",
   "metadata": {},
   "source": [
    "### Section 2: Comparing Ski Rental Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127cfe7-4506-47c1-9090-1e3b08da2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_df = []\n",
    "bins=100\n",
    "num_runs = 5\n",
    "conf = 0.9\n",
    "debug_dict = {} \n",
    "for i in range(num_runs):\n",
    "    indices = np.arange(len(X))\n",
    "    # First split: separate out test set (20% of data)\n",
    "    idx_temp, idx_test = train_test_split(\n",
    "        indices, test_size=0.20, random_state=i\n",
    "    )\n",
    "\n",
    "    # Second split: split remaining data into train and validation (0.25 = 20% of original 80%)\n",
    "    idx_train, idx_valid = train_test_split(\n",
    "        idx_temp, test_size=0.20, random_state=i\n",
    "    )\n",
    "\n",
    "    # regression \n",
    "    X_train = X_post_reg[idx_train]\n",
    "    X_valid = X_post_reg[idx_valid]\n",
    "    X_test = X_post_reg[idx_test]\n",
    "\n",
    "    y_train_cont = y[idx_train]\n",
    "    y_valid_cont = y[idx_valid]\n",
    "    y_test_cont = y[idx_test]\n",
    "\n",
    "    # continuous Y\n",
    "    # reg_model_name = md.get_best_regressor(X_train,\n",
    "    #                                        y_train,\n",
    "    #                                        X_valid,\n",
    "    #                                        y_valid)\n",
    "    reg_results_df = pd.DataFrame()\n",
    "    reg_model_name = 'NN'\n",
    "#     model = Pipeline(\n",
    "#         [\n",
    "#             (\"scalar\", StandardScaler()),\n",
    "#             #(reg_model_name, md.reg_dict[reg_model_name]())\n",
    "#             (reg_model_name, MLPRegressor(hidden_layer_sizes=(8,2),solver=\"sgd\",alpha=0.01))\n",
    "\n",
    "#         ]\n",
    "#     )\n",
    "    model = md.model_choice_regression(reg_model_name, X_train, y_train_cont)\n",
    "    rf = WrapRegressor(model)\n",
    "    rf.fit(X_train, y_train_cont)\n",
    "    rf.calibrate(X_valid, y_valid_cont)\n",
    "\n",
    "    conf_interval = rf.predict_int(X_test, confidence=conf)\n",
    "\n",
    "    reg_results_df['reg_pred_cont'] = model.predict(X_test)\n",
    "    reg_results_df['reg_low_cont'] = np.maximum(conf_interval[:, 0], 1e-5) # avoid negative numbers\n",
    "    reg_results_df['reg_high_cont'] = conf_interval[:, 1]\n",
    "    reg_results_df['y'] = y_test_cont\n",
    "\n",
    "    print(\"mean conf interval size: \", (conf_interval[:10, 1] - conf_interval[:10, 0]).mean())\n",
    "    \n",
    "    for b in [200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "        #b+=1300\n",
    "    #for b in [800, 900, 1000]:    \n",
    "        results_df = pd.DataFrame()\n",
    "\n",
    "        \n",
    "        y_train = y_train_cont > b \n",
    "        y_valid = y_valid_cont > b \n",
    "        y_test = y_test_cont > b \n",
    "            \n",
    "        # reg_model_name = md.get_best_regressor(X_train,\n",
    "        #                                        y_train_reg,\n",
    "        #                                        X_valid,\n",
    "        #                                        y_valid_reg)\n",
    "        model = md.model_choice_regression(reg_model_name, X_train, y_train)\n",
    "#         model = Pipeline(\n",
    "#             [\n",
    "#                 (\"scalar\", StandardScaler()),\n",
    "#                 #(reg_model_name, md.reg_dict[reg_model_name]())\n",
    "#                 (reg_model_name, MLPRegressor(hidden_layer_sizes=(8,2),solver=\"sgd\",alpha=0.01))\n",
    "\n",
    "#             ]\n",
    "#         )\n",
    "        rf = WrapRegressor(model)\n",
    "        rf.fit(X_train, y_train)\n",
    "        rf.calibrate(X_valid, y_valid)\n",
    "\n",
    "        conf_interval = rf.predict_int(X_test, confidence=conf)\n",
    "            \n",
    "        results_df['reg_pred'] = model.predict(X_test)\n",
    "        results_df['reg_low'] = np.maximum(conf_interval[:, 0], 1e-3)\n",
    "        results_df['reg_high'] = conf_interval[:, 1]\n",
    "\n",
    "        \n",
    "        results_df['y_bin'] = y_test\n",
    "        results_df['delta'] = 1 - conf\n",
    "        \n",
    "        # clf_model_name = md.get_best_classifier(X_train,\n",
    "        #                                        y_train,\n",
    "        #                                        X_valid,\n",
    "        #                                        y_valid)\n",
    "        clf_model_name = 'NN'\n",
    "        curr_clf = md.model_choice(clf_model_name, X_train, y_train)\n",
    "        curr_clf.fit(X_train, y_train)\n",
    "  \n",
    "    \n",
    "        # calibrate model\n",
    "        probs = curr_clf.predict_proba(X_test)[:, 1]\n",
    "        valid_probs = curr_clf.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        # get opt threshold: \n",
    "        fpr, tpr, thresholds = roc_curve(y_valid, valid_probs)\n",
    "        j_scores = tpr - fpr\n",
    "        optimal_idx = np.argmax(j_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        #ABALATION\n",
    "        results_df['clf_pred'] =  curr_clf.predict_proba(X_test)[:, 1] >= optimal_threshold\n",
    "        results_df['eps'] = 1 - (results_df['clf_pred'] == y_test).mean()\n",
    "        \n",
    "#         clf_model_name = 'NN'\n",
    "#         curr_clf = md.model_choice(clf_model_name, X_train, y_train)\n",
    "#         curr_clf.fit(X_train, y_train)\n",
    "#         probs = curr_clf.predict_proba(X_test)[:, 1]\n",
    "#         valid_probs = curr_clf.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        ## END ABALATION \n",
    "        \n",
    "        calibrator = cal.HistogramCalibrator(bins=bins)\n",
    "        calibrator.calibrate(y_prob=valid_probs, \n",
    "                             y_true=y_valid, \n",
    "                            subsample=True)\n",
    "        \n",
    "        y_cal_probs = calibrator.transform(probs)\n",
    "        \n",
    "        valid_probs = calibrator.transform(valid_probs)\n",
    "        _, _, _, _, alpha = ut.expected_calibration_error(prob_true=np.asarray(y_valid),\n",
    "                                             prob_pred=np.asarray(valid_probs),\n",
    "                                             num_bins=bins, \n",
    "                                             subsample=True)\n",
    "    \n",
    "        # results_df['clf_pred'] =  curr_clf.predict_proba(X_test)[:, 1] >= optimal_threshold\n",
    "        # results_df['eps'] = 1 - (results_df['clf_pred'] == y_test).mean()\n",
    "        # print(1 - (results_df['clf_pred'] == y_test).mean())\n",
    "        #print(f'acc: {(results_df['clf_pred'] == y_test).mean()}, vs {curr_clf.score(X_test, y_test)}')\n",
    "        \n",
    "        results_df['clf_prob'] = y_cal_probs\n",
    "        results_df['alpha'] = alpha\n",
    "        results_df['b'] = b\n",
    "        \n",
    "        results_df = pd.concat([reg_results_df, results_df], axis=1)\n",
    "\n",
    "        results_df['pip_cont_day'] = results_df.apply(\n",
    "            lambda row: sr.pip_alg(u=row['reg_high_cont'],l=row['reg_low_cont'], delta=row['delta'],b=row['b']), axis=1)\n",
    "        \n",
    "        results_df['pip_day'] = results_df.apply(\n",
    "            lambda row: sr.pip_alg(u=row['reg_high']*b,l=row['reg_low']*b, delta=row['delta'], b=row['b']), axis=1)\n",
    "        #results_df['pip_day'] = results_df['pip_day']*b\n",
    "\n",
    "        results_df['bin_day'] = results_df.apply(\n",
    "            lambda row: sr.regular_ski_rental(pred=row['clf_pred'], eps=row['eps'],b=row['b']), axis=1\n",
    "        )\n",
    "        results_df['cal_day'] = results_df.apply(\n",
    "            lambda row: sr.cal_ski_rental(pred=row['clf_prob'], alpha=row['alpha'], b=row['b']), axis=1\n",
    "        )\n",
    "        results_df['breakeven_day'] = b\n",
    "        results_df['breakeven2_day'] = 2*b\n",
    "          \n",
    "        results_df['pip_CR'] = sr.get_CR_df(results_df, 'pip_day')\n",
    "        results_df['pip_cont_CR'] = sr.get_CR_df(results_df, 'pip_cont_day')\n",
    "        results_df['bin_CR'] = sr.get_CR_df(results_df, 'bin_day')\n",
    "        results_df['breakeven_CR'] = sr.get_CR_df(results_df, 'breakeven_day')\n",
    "        results_df['breakeven2_CR'] = sr.get_CR_df(results_df, 'breakeven2_day')\n",
    "        results_df['cal_CR'] = sr.get_CR_df(results_df, 'cal_day')\n",
    "\n",
    "        CR_summary = results_df[['cal_CR', 'bin_CR','pip_CR', 'pip_cont_CR', 'breakeven_CR', 'breakeven2_CR']].mean().to_dict() \n",
    "        CR_summary['b'] = b\n",
    "        CR_summary['i'] = i\n",
    "        CR_summary['opt_thresh'] = optimal_threshold\n",
    "        CR_df.append(CR_summary)\n",
    "        \n",
    "        if i == 0: \n",
    "            debug_dict[b] = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc3269-6d05-4c8a-8581-d070d2acee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_df = pd.DataFrame(CR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b43ea-2a31-4e38-97d6-951ab38739b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_df.groupby('b').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968460e4-7d65-4701-a486-8c2301a72863",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_df.to_csv(\"ski_rental_final_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867934a-e872-4ad1-99a0-0a78efb38e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes= axes.flatten() \n",
    "melted_df = pd.melt(CR_df, \n",
    "                    # Keep b and i as id variables\n",
    "                    id_vars=['b', 'i'],\n",
    "                    # Select the CR columns to melt\n",
    "                    value_vars=['pip_CR', 'bin_CR', 'breakeven_CR', 'cal_CR'],\n",
    "                    #value_vars=['pip_CR', 'bin_CR', 'breakeven_CR', 'cal_CR'],\n",
    "                    # Name the new columns\n",
    "                    var_name='method',\n",
    "                    value_name='CR')\n",
    "\n",
    "sns.histplot(y, ax=axes[0])\n",
    "for q in [0.25, 0.5, 0.75]:\n",
    "    val = np.quantile(y, q)\n",
    "    axes[0].axvline(val, color='blue', linestyle='--')\n",
    "    axes[0].text(val, axes[0].get_ylim()[1], f'{val}', \n",
    "                 rotation=90, va='top', ha='right')\n",
    "axes[0].set_xlabel('target value')\n",
    "axes[0].set_title(f'Distribution of target values for {DATASET} dataset')\n",
    "\n",
    "sns.lineplot(data=melted_df,\n",
    "             x='b',\n",
    "             y='CR',\n",
    "             hue='method',\n",
    "             style='method',\n",
    "             marker='o', \n",
    "            ax=axes[1])  # This will add 95% confidence intervals\n",
    "\n",
    "axes[1].set_title(f'Comparison of CR Methods clf:{clf_model_name} reg:{reg_model_name} (OPT Threshold)')\n",
    "plt.savefig(f'clf{clf_model_name}-reg{reg_model_name}_CR.pdf')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf03bd6-6903-46fa-815e-07c120051f7f",
   "metadata": {},
   "source": [
    "## Debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f4502-725f-403e-bb5e-af3439e2aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=600\n",
    "results_df = debug_dict[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9493cb-7765-4a42-b93f-cc4cdc262308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug pip \n",
    "row = results_df.iloc[9]\n",
    "print(row[['pip_cont_CR', 'cal_CR', 'pip_CR']])\n",
    "print('cal', row['cal_day'], row['clf_prob'], row['reg_high_cont'], row['y'])\n",
    "print('cont', row['pip_cont_day'], row['reg_low_cont'], row['reg_high_cont'], row['y'])\n",
    "print('disc', row['pip_day'], row['reg_low']*row['b'], row['reg_high']*row['b'], row['y'])\n",
    "print(sr.pip_alg(u=row['reg_high_cont'], \n",
    "           l=row['reg_low_cont'], \n",
    "           delta=row['delta'], \n",
    "           b=row['b']))\n",
    "print(sr.pip_alg(u=row['reg_high']*row['b'], \n",
    "           l=row['reg_low']*row['b'], \n",
    "           delta=row['delta'], \n",
    "           b=row['b']))\n",
    "\n",
    "# CR \n",
    "sr.get_CR(buy=row['pip_day'],\n",
    "            y=row['y'],\n",
    "            b=row['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f78d64-1a46-4d87-8b7b-ce2e883abdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare df \n",
    "compare_CR='bin_CR'\n",
    "compare_day = 'bin_day'\n",
    "results_df['worse'] = results_df['cal_CR'] > results_df[compare_CR]\n",
    "results_df['better'] = results_df['cal_CR'] < results_df[compare_CR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c369ad7-edd2-4599-9101-a2cb07c2a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_df = results_df[results_df['worse'] == True]\n",
    "worst_df.groupby(['cal_CR', 'clf_prob', compare_CR, 'y', 'cal_day', compare_day]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75815b-c991-44d5-bada-a74d43994898",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes= axes.flatten() \n",
    "sns.histplot(data=results_df, x='cal_day', y=compare_day, ax=axes[0]).set_title(\"buy day\")\n",
    "sns.histplot(data=results_df, x='cal_CR', y=compare_CR, ax=axes[1]).set_title(\"CR\")\n",
    "plt.suptitle(f\"cal CR vs {compare_CR} for b={b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d5495-be33-4637-8469-185c16efd700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54aed81-b718-497f-9e1c-aae26bf3ddb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
